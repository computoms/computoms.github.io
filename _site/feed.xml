<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en-GB"><generator uri="https://jekyllrb.com/" version="3.8.5">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" hreflang="en-GB" /><updated>2019-04-04T23:32:53+02:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">CompuToms</title><subtitle>Welcome to CompuToms website!</subtitle><author><name>CompuToms</name></author><entry><title type="html">Data storage</title><link href="http://localhost:4000/storage/2019/03/31/Data-storage/" rel="alternate" type="text/html" title="Data storage" /><published>2019-03-31T21:00:00+02:00</published><updated>2019-03-31T21:00:00+02:00</updated><id>http://localhost:4000/storage/2019/03/31/Data-storage</id><content type="html" xml:base="http://localhost:4000/storage/2019/03/31/Data-storage/">&lt;p&gt;&lt;img src=&quot;https://i2.wp.com/computoms.com/wp-content/uploads/2019/03/Illustration.png?resize=768%2C283&amp;amp;ssl=1&quot; alt=&quot;Binary representation illustration&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://computoms.com/2019/03/31/data-storage/&quot;&gt;This article is also available on computoms.com&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;data-structures-algorithms&quot;&gt;Data structures, algorithms&lt;/h2&gt;

&lt;p&gt;When speaking about algorithms, “data structures” is almost always the expression that comes along. Data structures and algorithms go in pair. An algorithm is fundamentally the manipulation of data from one form to another. The way we store this data is usually one of the important aspects to look at when designing an algorithm and looking at its performance.&lt;/p&gt;

&lt;figure class=&quot;figure  figure--center&quot;&gt;
  &lt;img class=&quot;image&quot; src=&quot;https://i0.wp.com/computoms.com/wp-content/uploads/2019/03/Untitled-Diagram.png?w=431&amp;amp;ssl=1&quot; alt=&quot;Parallel between data structures / algorithms and memory / processor&quot; width=&quot;&quot; height=&quot;&quot; /&gt;
  &lt;figcaption class=&quot;caption&quot;&gt;Parallel between data structures / algorithms and memory / processor&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Choosing the right data structure for your algorithm or program usually involves thinking about how to efficiently store and retrieve the data associated to your problem.&lt;/p&gt;

&lt;p&gt;To correctly understand how the different data structures work, it is then important to know how we store data in a computer.&lt;/p&gt;

&lt;h1 id=&quot;computer-memory&quot;&gt;Computer memory&lt;/h1&gt;

&lt;p&gt;Basically, there are three “data storage” types in a computer:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Hard drive storage&lt;/li&gt;
  &lt;li&gt;Random-access memory&lt;/li&gt;
  &lt;li&gt;Processor cache memory&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;hard-drive&quot;&gt;Hard drive&lt;/h2&gt;

&lt;p&gt;Hard drives are non-volatile data storage. This means that data remains unchanged when power is turned off. It is usually the cheapest and biggest memory in a computer, and is where you typically save your files, photos and other data you want to keep. One of the disadvantage of this type of memory is that it is usually slow (mostly due to hardware implementation as we’ll see in a futur post).&lt;/p&gt;

&lt;h2 id=&quot;random-access-memory&quot;&gt;Random-access memory&lt;/h2&gt;

&lt;p&gt;Random-access memory (RAM) is where the non-persistent data is stored on your computer. It is a volatile data storage. When starting a program, the operating system loads the content of the program into the RAM memory and the program’s data is stored within the RAM memory.&lt;/p&gt;

&lt;p&gt;The RAM memory is relatively fast to access, as we’ll see below, but &lt;strong&gt;looses its data when power is turned off&lt;/strong&gt;. As we’ll see in futur posts on the hardware implementation of RAM memory, it needs a certain amount of power to be refreshed and to avoid loosing its data.&lt;/p&gt;

&lt;p&gt;This is the memory type we’ll be interested when talking about data structures. Its most common hardware implementation is interesting to study as it allows to have a clearer insight into how data structures actually work and why some are better than others for solving particular problems.&lt;/p&gt;

&lt;h2 id=&quot;processor-cache-memory&quot;&gt;Processor cache memory&lt;/h2&gt;

&lt;p&gt;In order to have an even faster memory, processors implements a part of memory directly onto their chips, called the cache memory. Its hardware implementation and location (closer to logic area of the processor) makes it the fastest storage accessible from the processor. This memory is also a type of random-access memory, and shares its drawback (loss of data when power turns off).&lt;/p&gt;

&lt;p&gt;Before data is loaded into processor registers from the RAM memory, it is actually transferred from RAM to cache memory. Knowing this is important to understand the performance of data structures and some algorithms.&lt;/p&gt;

&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;

&lt;p&gt;Here is a summary of the characteristics of each computer memory.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt; &lt;/th&gt;
      &lt;th&gt;Data access&lt;/th&gt;
      &lt;th&gt;Persistence&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Hard drive&lt;/td&gt;
      &lt;td&gt;Slowest&lt;/td&gt;
      &lt;td&gt;Persistent&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;RAM&lt;/td&gt;
      &lt;td&gt;Fast&lt;/td&gt;
      &lt;td&gt;Non-persistent&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Processor cache&lt;/td&gt;
      &lt;td&gt;Fastest&lt;/td&gt;
      &lt;td&gt;Non-persistent&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;br /&gt;
Next posts will present an overview of the standard hardware implementations of these memories in order to have a better understanding of how they work and how they can be used.&lt;/p&gt;</content><author><name>CompuToms</name></author><summary type="html">This article is also available on computoms.com Data structures, algorithms When speaking about algorithms, “data structures” is almost always the expression that comes along. Data structures and algorithms go in pair. An algorithm is fundamentally the manipulation of data from one form to another. The way we store this data is usually one of the important aspects to look at when designing an algorithm and looking at its performance. Parallel between data structures / algorithms and memory / processor Choosing the right data structure for your algorithm or program usually involves thinking about how to efficiently store and retrieve the data associated to your problem. To correctly understand how the different data structures work, it is then important to know how we store data in a computer. Computer memory Basically, there are three “data storage” types in a computer: Hard drive storage Random-access memory Processor cache memory Hard drive Hard drives are non-volatile data storage. This means that data remains unchanged when power is turned off. It is usually the cheapest and biggest memory in a computer, and is where you typically save your files, photos and other data you want to keep. One of the disadvantage of this type of memory is that it is usually slow (mostly due to hardware implementation as we’ll see in a futur post). Random-access memory Random-access memory (RAM) is where the non-persistent data is stored on your computer. It is a volatile data storage. When starting a program, the operating system loads the content of the program into the RAM memory and the program’s data is stored within the RAM memory. The RAM memory is relatively fast to access, as we’ll see below, but looses its data when power is turned off. As we’ll see in futur posts on the hardware implementation of RAM memory, it needs a certain amount of power to be refreshed and to avoid loosing its data. This is the memory type we’ll be interested when talking about data structures. Its most common hardware implementation is interesting to study as it allows to have a clearer insight into how data structures actually work and why some are better than others for solving particular problems. Processor cache memory In order to have an even faster memory, processors implements a part of memory directly onto their chips, called the cache memory. Its hardware implementation and location (closer to logic area of the processor) makes it the fastest storage accessible from the processor. This memory is also a type of random-access memory, and shares its drawback (loss of data when power turns off). Before data is loaded into processor registers from the RAM memory, it is actually transferred from RAM to cache memory. Knowing this is important to understand the performance of data structures and some algorithms. Summary Here is a summary of the characteristics of each computer memory.   Data access Persistence Hard drive Slowest Persistent RAM Fast Non-persistent Processor cache Fastest Non-persistent Next posts will present an overview of the standard hardware implementations of these memories in order to have a better understanding of how they work and how they can be used.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/default-social-image.png" /></entry></feed>